{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-19T09:16:54.952951Z",
     "start_time": "2017-05-19T09:16:53.369932Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import shutil\n",
    "import numpy as np\n",
    "import threading\n",
    "# import keras\n",
    "import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "import selectivesearch\n",
    "importlib.reload(selectivesearch)\n",
    "from selectivesearch import get_selective_search_regions\n",
    "\n",
    "import pickle\n",
    "import PIL\n",
    "\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import pascal_voc_reader\n",
    "\n",
    "import bbox_transform\n",
    "importlib.reload(bbox_transform)\n",
    "from bbox_transform import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as weight_init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import rcnn_utils\n",
    "importlib.reload(rcnn_utils)\n",
    "from rcnn_utils import *\n",
    "import data_utils\n",
    "importlib.reload(data_utils)\n",
    "from data_utils import *\n",
    "from nms.nms_wrapper import nms\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import voc_eval; importlib.reload(voc_eval)\n",
    "from voc_eval import voc_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-19T09:16:56.200376Z",
     "start_time": "2017-05-19T09:16:55.993254Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def unnormalize_deltas(deltas, dataset):\n",
    "    ''' Unnormalize deltas using mean and targets from dataset.\n",
    "    Args:\n",
    "        deltas: A ndarray with size (batch_size, num_fg_classes * 4)\n",
    "        dataset: The current dataset. Used to retrieve the mean and stds.\n",
    "    Returns:\n",
    "        The unnormalized deltas.\n",
    "    '''\n",
    "    # Mean and std skip first row (its the background class).\n",
    "    # Then get shaped into num_fg_classes * 4 to be added to the deltas.\n",
    "    means = dataset.targets_mean[1:].reshape(-1)\n",
    "    stds = dataset.targets_std[1:].reshape(-1)\n",
    "    return deltas * stds + means\n",
    "\n",
    "\n",
    "def test_image(image, rois, dataset,\n",
    "               top_class_only=True,\n",
    "               class_detection_thresh=0.05,\n",
    "               nms_thresh=0.3):\n",
    "    ''' Test a single image on the net.\n",
    "    Args:\n",
    "        image: A preprocessed image or precomputed features of \n",
    "            the image. As ndarray.\n",
    "        rois: RoIs for the image. Ndarray: (image_index, x1, y1, x2, y2)\n",
    "        dataset: The currently used dataset.\n",
    "        top_class_only: Whether to use only top class for each roi,\n",
    "            or any class over a certain threshhold.\n",
    "        class_detection_thresh: If the softmax for this class is \n",
    "            above class_detection_thresh, it's considered detected\n",
    "            in the roi.\n",
    "    '''\n",
    "    image_var = np_to_var(image.astype(np.float32))\n",
    "    # image_var = Variable(image.cuda())\n",
    "    rois_var = np_to_var(rois.astype(np.int32))\n",
    "\n",
    "    # Run the img through the network\n",
    "    out = model(image_var, rois_var)\n",
    "    # predicted deltas\n",
    "    deltas = out[1].data.cpu().numpy()\n",
    "    deltas = unnormalize_deltas(deltas, dataset)\n",
    "\n",
    "    # transform rois using predicted deltas\n",
    "    boxes = rois[:, 1:]\n",
    "    bboxes_inv_transformed = bbox_transform_inv(boxes, deltas)\n",
    "\n",
    "    class_probas, class_indexes = torch.max(out[0], 1)\n",
    "    indexes_np = np.squeeze(class_indexes.data.cpu().numpy())\n",
    "#     print('Total FG RoIs Detected: ', np.sum(indexes_np > 0))\n",
    "\n",
    "    scores = out[0].data.cpu().numpy()\n",
    "    scores = np.exp(scores)\n",
    "\n",
    "    # clip rois to image size\n",
    "    bboxes_inv_transformed = clip_boxes(bboxes_inv_transformed,\n",
    "                                        dataset.im_size)\n",
    "\n",
    "    all_boxes = nms_boxes(bboxes_inv_transformed, scores,\n",
    "                          top_class_only=top_class_only,\n",
    "                          class_detection_thresh=class_detection_thresh,\n",
    "                          nms_thresh=nms_thresh)\n",
    "    return all_boxes\n",
    "\n",
    "\n",
    "def nms_boxes(boxes, scores, num_classes=21,\n",
    "              top_class_only=False,\n",
    "              class_detection_thresh=0.05,\n",
    "              nms_thresh=0.3):\n",
    "    all_boxes = [[] for _ in range(num_classes)]\n",
    "    # skip j = 0, because it's the background class\n",
    "    for class_id in range(1, num_classes):\n",
    "        # Whether to use only the top class for each box or\n",
    "        # all classes over a certain threshhold.\n",
    "        if top_class_only:\n",
    "            detection_criterion = (np.argmax(scores, axis=1) == class_id)\n",
    "        else:\n",
    "            detection_criterion = (\n",
    "                scores[:, class_id] > class_detection_thresh)\n",
    "        class_detected_indexes = np.where(detection_criterion)[0]\n",
    "\n",
    "        cls_scores = scores[class_detected_indexes, class_id]\n",
    "        class_box_start = (class_id - 1) * 4\n",
    "        class_box_end = class_box_start + 4\n",
    "        cls_boxes = boxes[class_detected_indexes,\n",
    "                          class_box_start:class_box_end]\n",
    "\n",
    "        cls_dets = np.hstack((cls_boxes, cls_scores[:, np.newaxis])) \\\n",
    "            .astype(np.float32, copy=False)\n",
    "\n",
    "        if len(cls_dets) > 1:\n",
    "            keep = nms(cls_dets, nms_thresh, force_cpu=True)\n",
    "            cls_dets = cls_dets[keep, :]\n",
    "        all_boxes[class_id] = cls_dets\n",
    "    return all_boxes\n",
    "\n",
    "\n",
    "def get_display_boxes(all_boxes):\n",
    "    display_boxes = []\n",
    "    display_classes = []\n",
    "    for class_id, class_boxes in enumerate(all_boxes):\n",
    "        for box in class_boxes:\n",
    "            display_boxes.append(box)\n",
    "            display_classes.append(class_id)\n",
    "    return np.asarray(display_boxes), np.asarray(display_classes)\n",
    "\n",
    "\n",
    "def display_detections(rois, classes, dataset, show_gt_boxes=True):\n",
    "    ''' Display detected foreground rois for the previous image in dataset.\n",
    "    Args:\n",
    "        rois: Detected RoIs as ndarray of (x, y, w, h)\n",
    "        classes: Class labels of each RoI as ndarray of class_id.\n",
    "        dataset: The dataset that was used to get the image, we will get \n",
    "            the previous image from it and display the rois on it.\n",
    "        show_gt_boxes: Show the ground truth boxes as well.\n",
    "    '''\n",
    "    detected_roi = np.append(rois,\n",
    "                             classes[:, None],\n",
    "                             axis=1)\n",
    "    index = dataset.index - 1\n",
    "    if show_gt_boxes:\n",
    "        gt_boxes = dataset.gt_boxes[index]\n",
    "    else:\n",
    "        gt_boxes = None\n",
    "\n",
    "    image_arr = dataset.images[index]\n",
    "    image = PIL.Image.fromarray(image_arr.astype('uint8'))\n",
    "\n",
    "#     for class_id in detected_roi[:, 4]:\n",
    "#         print(dataset.class_id_to_name[class_id])\n",
    "\n",
    "    display_image_regions(image, detected_roi, gt_boxes,\n",
    "                          class_id_to_name=dataset.class_id_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T12:28:09.248871Z",
     "start_time": "2017-05-17T12:26:51.138128Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n",
      "[Errno 2] No such file or directory: './data/VOC2012/ImageSets/Main/test.txt'\n"
     ]
    }
   ],
   "source": [
    "image_size = (500, 500)\n",
    "all_data = RCNN_All_Data(image_size)\n",
    "# dataset.unload_set('valid')\n",
    "train = RCNN_Set(all_data, 'train')\n",
    "valid = RCNN_Set(all_data, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T15:19:39.407591Z",
     "start_time": "2017-05-17T15:19:39.402083Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T12:28:12.344897Z",
     "start_time": "2017-05-17T12:28:09.268740Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Init the model\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "model = Fast_RCNN_model(dropout_p=0.1).cuda()\n",
    "model.train(mode=False)\n",
    "fast_rcnn_weights_init(model)\n",
    "load_weights(model, 'intermediate/voc/weights-regression-300.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a single image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T16:02:45.752032Z",
     "start_time": "2017-05-17T16:02:45.746078Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-19T09:17:07.718077Z",
     "start_time": "2017-05-19T09:17:03.696373Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%debug\n",
    "images, rois, targets = dataset.next_batch(\n",
    "    images_per_batch=1,\n",
    "    roi_batch_size=64,\n",
    "    use_features=True,\n",
    "    loop_over=False)\n",
    "\n",
    "all_boxes = test_image(images, rois, dataset, top_class_only=False,\n",
    "                       class_detection_thresh=0.05, nms_thresh=0.3)\n",
    "display_boxes, display_classes = get_display_boxes(all_boxes)\n",
    "if len(display_boxes) == 0:\n",
    "    print('Nothing detected for this image.')\n",
    "else:\n",
    "    display_detections(\n",
    "        RCNN_Set.transform_regions_width_height(display_boxes),\n",
    "        display_classes,\n",
    "        dataset, show_gt_boxes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Evaluate a single image AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt_boxes = # load from file\n",
    "for all classes\n",
    "    for each detection \n",
    "        compute iou of detection and gt boxes for this class\n",
    "        get max iou\n",
    "        \n",
    "        \n",
    "        if ovmax > ovthresh:\n",
    "            if not R['difficult'][jmax]:\n",
    "                if not R['det'][jmax]:\n",
    "                    tp[d] = 1.\n",
    "                    R['det'][jmax] = 1\n",
    "                else:\n",
    "                    fp[d] = 1.\n",
    "        else:\n",
    "            fp[d] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T15:19:20.077793Z",
     "start_time": "2017-05-17T15:19:20.056371Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(dataset):\n",
    "\n",
    "    images_per_batch = 1\n",
    "    roi_batch_size = 64\n",
    "    n_batches = (dataset.sample_count // images_per_batch)\n",
    "    \n",
    "    all_boxes = [[[] for _ in range(n_batches)]\n",
    "                 for _ in range(dataset.num_classes)]\n",
    "    \n",
    "    for image_index in tqdm.tqdm_notebook(range(n_batches)):\n",
    "        # Get next batch\n",
    "        batch = dataset.next_batch(images_per_batch=images_per_batch,\n",
    "                          roi_batch_size=roi_batch_size,\n",
    "                          use_features=True, loop_over=False)\n",
    "        images, rois, targets = batch\n",
    "        if len(images) == 0 or len(rois) == 0 or len(targets) == 0:\n",
    "            # no more samples\n",
    "            break\n",
    "\n",
    "        # Forward Pass\n",
    "        image_boxes = test_image(images, rois, dataset, top_class_only=False,\n",
    "                       class_detection_thresh=0.05, nms_thresh=0.3)\n",
    "\n",
    "        for class_id, class_boxes in enumerate(image_boxes):\n",
    "            all_boxes[class_id][image_index] = class_boxes\n",
    "\n",
    "    return all_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T15:19:42.055445Z",
     "start_time": "2017-05-17T15:19:42.049540Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T15:22:12.445127Z",
     "start_time": "2017-05-17T15:19:43.990861Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb15fbe870c4533ad7a02bc324095d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_boxes = test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T14:45:26.836535Z",
     "start_time": "2017-05-17T14:45:26.747531Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = 'intermediate/voc/'\n",
    "det_file = os.path.join(output_dir, 'detections_no_reg.pkl')\n",
    "with open(det_file, 'wb') as f:\n",
    "    pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T15:18:20.582956Z",
     "start_time": "2017-05-17T15:18:20.580412Z"
    }
   },
   "outputs": [],
   "source": [
    "_classes = [dataset.class_id_to_name[index] \n",
    "            for index in range(dataset.num_classes)]\n",
    "_devkit_path = 'data/VOCdevkit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T15:22:23.167651Z",
     "start_time": "2017-05-17T15:22:23.151979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12871"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_filenames = (np.array(dataset.filenames)\n",
    "                       [dataset.enough_samples_mask]\n",
    "                       [dataset.train_indexes])\n",
    "\n",
    "names_only = [name.replace('./data/VOC2012/JPEGImages/',''\n",
    "                          ).replace('.jpg', '')\n",
    "              for name in dataset_filenames]\n",
    "len(names_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T15:29:26.708144Z",
     "start_time": "2017-05-17T15:29:26.696404Z"
    }
   },
   "outputs": [],
   "source": [
    "imageset_filename = 'slav_train.txt'\n",
    "save_dir = 'data/VOCdevkit/VOC2012/ImageSets/Main/'\n",
    "fullpath = os.path.join(save_dir, imageset_filename)\n",
    "with open(fullpath, 'w') as f:\n",
    "    for line in names_only:\n",
    "        f.write('{:s}\\n'.format(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T15:29:39.034659Z",
     "start_time": "2017-05-17T15:29:37.443321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing bg VOC results file\n",
      "Writing person VOC results file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slav/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:10: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing bottle VOC results file\n",
      "Writing motorbike VOC results file\n",
      "Writing sheep VOC results file\n",
      "Writing car VOC results file\n",
      "Writing bus VOC results file\n",
      "Writing dog VOC results file\n",
      "Writing horse VOC results file\n",
      "Writing train VOC results file\n",
      "Writing cow VOC results file\n",
      "Writing aeroplane VOC results file\n",
      "Writing bird VOC results file\n",
      "Writing pottedplant VOC results file\n",
      "Writing bicycle VOC results file\n",
      "Writing cat VOC results file\n",
      "Writing chair VOC results file\n",
      "Writing boat VOC results file\n",
      "Writing sofa VOC results file\n",
      "Writing diningtable VOC results file\n",
      "Writing tvmonitor VOC results file\n"
     ]
    }
   ],
   "source": [
    "_write_voc_results_file(_classes, names_only, all_boxes, _devkit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T16:38:39.876218Z",
     "start_time": "2017-05-17T16:38:32.872669Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP for person = 0.0755\n",
      "AP for bottle = 0.0184\n",
      "AP for motorbike = 0.1016\n",
      "AP for sheep = 0.0458\n",
      "AP for car = 0.0461\n",
      "AP for bus = 0.0990\n",
      "AP for dog = 0.1293\n",
      "AP for horse = 0.0751\n",
      "AP for train = 0.1066\n",
      "AP for cow = 0.0529\n",
      "AP for aeroplane = 0.0629\n",
      "AP for bird = 0.0832\n",
      "AP for pottedplant = 0.0658\n",
      "AP for bicycle = 0.0639\n",
      "AP for cat = 0.2040\n",
      "AP for chair = 0.0323\n",
      "AP for boat = 0.0339\n",
      "AP for sofa = 0.0866\n",
      "AP for diningtable = 0.0457\n",
      "AP for tvmonitor = 0.0961\n",
      "Mean AP = 0.0762\n",
      "~~~~~~~~\n",
      "Results:\n",
      "0.075\n",
      "0.018\n",
      "0.102\n",
      "0.046\n",
      "0.046\n",
      "0.099\n",
      "0.129\n",
      "0.075\n",
      "0.107\n",
      "0.053\n",
      "0.063\n",
      "0.083\n",
      "0.066\n",
      "0.064\n",
      "0.204\n",
      "0.032\n",
      "0.034\n",
      "0.087\n",
      "0.046\n",
      "0.096\n",
      "0.076\n",
      "~~~~~~~~\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Results computed with the **unofficial** Python eval code.\n",
      "Results should be very close to the official MATLAB eval code.\n",
      "Recompute with `./tools/reval.py --matlab ...` for your paper.\n",
      "-- Thanks, The Management\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "_do_python_eval(_devkit_path, _classes, imageset_filename=imageset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T14:47:54.444635Z",
     "start_time": "2017-05-17T14:47:54.431654Z"
    }
   },
   "outputs": [],
   "source": [
    "def _write_voc_results_file(classes, filenames, all_boxes, _devkit_path):\n",
    "    for cls_ind, cls in enumerate(classes):\n",
    "        if cls == 'bg':\n",
    "            continue\n",
    "        print('Writing {} VOC results file'.format(cls))\n",
    "        filename = _get_voc_results_file_template(_devkit_path).format(cls)\n",
    "        with open(filename, 'wt') as f:\n",
    "            for im_ind, index in enumerate(filenames):\n",
    "                dets = all_boxes[cls_ind][im_ind]\n",
    "                if dets == []:\n",
    "                    continue\n",
    "                # the VOCdevkit expects 1-based indices\n",
    "                for k in range(dets.shape[0]):\n",
    "                    f.write('{:s} {:.3f} {:.1f} {:.1f} {:.1f} {:.1f}\\n'.\n",
    "                            format(index, dets[k, -1],\n",
    "                                   dets[k, 0] + 1, dets[k, 1] + 1,\n",
    "                                   dets[k, 2] + 1, dets[k, 3] + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T14:49:02.410974Z",
     "start_time": "2017-05-17T14:49:02.395899Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_voc_results_file_template(_devkit_path):\n",
    "    # VOCdevkit/results/VOC2007/Main/<comp_id>_det_test_aeroplane.txt\n",
    "    filename = '_det_' + 'trainval' + '_{:s}.txt'\n",
    "    path = os.path.join(\n",
    "        _devkit_path,\n",
    "        'results',\n",
    "        'VOC2012',\n",
    "        'Main',\n",
    "        filename)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T15:28:56.386447Z",
     "start_time": "2017-05-17T15:28:56.307326Z"
    }
   },
   "outputs": [],
   "source": [
    "def _do_python_eval(_devkit_path, _classes, output_dir = 'output', \n",
    "                   imageset_filename='slav_train.txt'):\n",
    "    annopath = os.path.join(\n",
    "        _devkit_path,\n",
    "        'VOC2012',\n",
    "        'Annotations',\n",
    "        '{:s}.xml')\n",
    "    imagesetfile = os.path.join(\n",
    "        _devkit_path,\n",
    "        'VOC2012',\n",
    "        'ImageSets',\n",
    "        'Main',\n",
    "        imageset_filename)\n",
    "    cachedir = os.path.join(_devkit_path, 'annotations_cache')\n",
    "    aps = []\n",
    "    # The PASCAL VOC metric changed in 2010\n",
    "    use_07_metric = False\n",
    "\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    for i, cls in enumerate(_classes):\n",
    "        if cls == 'bg':\n",
    "            continue\n",
    "        filename = _get_voc_results_file_template(_devkit_path).format(cls)\n",
    "        rec, prec, ap = voc_eval(\n",
    "            filename, annopath, imagesetfile, cls, cachedir, ovthresh=0.5,\n",
    "            use_07_metric=use_07_metric)\n",
    "        aps += [ap]\n",
    "        print('AP for {} = {:.4f}'.format(cls, ap))\n",
    "        with open(os.path.join(output_dir, cls + '_pr.pkl'), 'wb') as f:\n",
    "            pickle.dump({'rec': rec, 'prec': prec, 'ap': ap}, f)\n",
    "    print('Mean AP = {:.4f}'.format(np.mean(aps)))\n",
    "    print('~~~~~~~~')\n",
    "    print('Results:')\n",
    "    for ap in aps:\n",
    "        print('{:.3f}'.format(ap))\n",
    "    print('{:.3f}'.format(np.mean(aps)))\n",
    "    print('~~~~~~~~')\n",
    "    print('')\n",
    "    print('--------------------------------------------------------------')\n",
    "    print('Results computed with the **unofficial** Python eval code.')\n",
    "    print('Results should be very close to the official MATLAB eval code.')\n",
    "    print('Recompute with `./tools/reval.py --matlab ...` for your paper.')\n",
    "    print('-- Thanks, The Management')\n",
    "    print('--------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-16T19:44:07.075886Z",
     "start_time": "2017-05-16T19:44:07.072345Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO check how we perform with and without regression targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 420,
   "position": {
    "height": "442px",
    "left": "1055px",
    "right": "20px",
    "top": "120px",
    "width": "336px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
