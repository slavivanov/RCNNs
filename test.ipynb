{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T11:20:44.950516Z",
     "start_time": "2017-05-17T11:20:44.913461Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import shutil\n",
    "import numpy as np\n",
    "import threading\n",
    "# import keras\n",
    "import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "import selectivesearch\n",
    "importlib.reload(selectivesearch)\n",
    "from selectivesearch import get_selective_search_regions\n",
    "\n",
    "import PIL\n",
    "\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "\n",
    "import pascal_voc_reader\n",
    "\n",
    "import bbox_transform\n",
    "importlib.reload(bbox_transform)\n",
    "from bbox_transform import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as weight_init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import rcnn_utils\n",
    "importlib.reload(rcnn_utils)\n",
    "from rcnn_utils import *\n",
    "import data_utils\n",
    "importlib.reload(data_utils)\n",
    "from data_utils import *\n",
    "from nms.nms_wrapper import nms\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T11:28:15.995099Z",
     "start_time": "2017-05-17T11:28:15.781280Z"
    },
    "code_folding": [
     15
    ]
   },
   "outputs": [],
   "source": [
    "def unnormalize_deltas(deltas, dataset):\n",
    "    ''' Unnormalize deltas using mean and targets from dataset.\n",
    "    Args:\n",
    "        deltas: A ndarray with size (batch_size, num_fg_classes * 4)\n",
    "        dataset: The current dataset. Used to retrieve the mean and stds.\n",
    "    Returns:\n",
    "        The unnormalized deltas.\n",
    "    '''\n",
    "    # Mean and std skip first row (its the background class).\n",
    "    # Then get shaped into num_fg_classes * 4 to be added to the deltas.\n",
    "    means = dataset.targets_mean[1:].reshape(-1)\n",
    "    stds = dataset.targets_std[1:].reshape(-1)\n",
    "    return deltas * stds + means\n",
    "\n",
    "\n",
    "def test_image(image, rois, dataset,\n",
    "               top_class_only=True,\n",
    "               class_detection_thresh=0.05,\n",
    "               nms_thresh=0.3):\n",
    "    ''' Test a single image on the net.\n",
    "    Args:\n",
    "        image: A preprocessed image or precomputed features of \n",
    "            the image. As ndarray.\n",
    "        rois: RoIs for the image. Ndarray: (image_index, x1, y1, x2, y2)\n",
    "        dataset: The currently used dataset.\n",
    "        top_class_only: Whether to use only top class for each roi,\n",
    "            or any class over a certain threshhold.\n",
    "        class_detection_thresh: If the softmax for this class is \n",
    "            above class_detection_thresh, it's considered detected\n",
    "            in the roi.\n",
    "    '''\n",
    "    image_var = np_to_var(image.astype(np.float32))\n",
    "    # image_var = Variable(image.cuda())\n",
    "    rois_var = np_to_var(rois.astype(np.int32))\n",
    "\n",
    "    # Run the img through the network\n",
    "    out = model(image_var, rois_var)\n",
    "    # predicted deltas\n",
    "    deltas = out[1].data.cpu().numpy()\n",
    "    deltas = unnormalize_deltas(deltas, dataset)\n",
    "\n",
    "    # transform rois using predicted deltas\n",
    "    boxes = rois[:, 1:]\n",
    "    bboxes_inv_transformed = bbox_transform_inv(boxes, deltas)\n",
    "\n",
    "    class_probas, class_indexes = torch.max(out[0], 1)\n",
    "    indexes_np = np.squeeze(class_indexes.data.cpu().numpy())\n",
    "    print('Total FG RoIs Detected: ', np.sum(indexes_np > 0))\n",
    "\n",
    "    scores = out[0].data.cpu().numpy()\n",
    "    scores = np.exp(scores)\n",
    "\n",
    "    # clip rois to image size\n",
    "    bboxes_inv_transformed = clip_boxes(bboxes_inv_transformed,\n",
    "                                        dataset.im_size)\n",
    "\n",
    "    all_boxes = nms_boxes(bboxes_inv_transformed, scores,\n",
    "                          top_class_only=top_class_only,\n",
    "                          class_detection_thresh=class_detection_thresh,\n",
    "                          nms_thresh=nms_thresh)\n",
    "    return all_boxes\n",
    "\n",
    "\n",
    "def nms_boxes(boxes, scores, num_classes=21,\n",
    "              top_class_only=False,\n",
    "              class_detection_thresh=0.05,\n",
    "              nms_thresh=0.3):\n",
    "    all_boxes = [[] for _ in range(num_classes)]\n",
    "    # skip j = 0, because it's the background class\n",
    "    for class_id in range(1, num_classes):\n",
    "        # Whether to use only the top class for each box or\n",
    "        # all classes over a certain threshhold.\n",
    "        if top_class_only:\n",
    "            detection_criterion = (np.argmax(scores, axis=1) == class_id)\n",
    "        else:\n",
    "            detection_criterion = (\n",
    "                scores[:, class_id] > class_detection_thresh)\n",
    "        class_detected_indexes = np.where(detection_criterion)[0]\n",
    "\n",
    "        cls_scores = scores[class_detected_indexes, class_id]\n",
    "        class_box_start = (class_id - 1) * 4\n",
    "        class_box_end = class_box_start + 4\n",
    "        cls_boxes = boxes[class_detected_indexes,\n",
    "                          class_box_start:class_box_end]\n",
    "\n",
    "        cls_dets = np.hstack((cls_boxes, cls_scores[:, np.newaxis])) \\\n",
    "            .astype(np.float32, copy=False)\n",
    "\n",
    "        if len(cls_dets) > 1:\n",
    "            keep = nms(cls_dets, nms_thresh, force_cpu=True)\n",
    "            cls_dets = cls_dets[keep, :]\n",
    "        all_boxes[class_id] = cls_dets\n",
    "    return all_boxes\n",
    "\n",
    "\n",
    "def get_display_boxes(all_boxes):\n",
    "    display_boxes = []\n",
    "    display_classes = []\n",
    "    for class_id, class_boxes in enumerate(all_boxes):\n",
    "        for box in class_boxes:\n",
    "            display_boxes.append(box)\n",
    "            display_classes.append(class_id)\n",
    "    return np.asarray(display_boxes), np.asarray(display_classes)\n",
    "\n",
    "\n",
    "def display_detections(rois, classes, dataset, show_gt_boxes=True):\n",
    "    ''' Display detected foreground rois for the previous image in dataset.\n",
    "    Args:\n",
    "        rois: Detected RoIs as ndarray of (x, y, w, h)\n",
    "        classes: Class labels of each RoI as ndarray of class_id.\n",
    "        dataset: The dataset that was used to get the image, we will get \n",
    "            the previous image from it and display the rois on it.\n",
    "        show_gt_boxes: Show the ground truth boxes as well.\n",
    "    '''\n",
    "    detected_roi = np.append(rois,\n",
    "                             classes[:, None],\n",
    "                             axis=1)\n",
    "    index = dataset.index - 1\n",
    "    if show_gt_boxes:\n",
    "        gt_boxes = dataset.gt_boxes[index]\n",
    "    else:\n",
    "        gt_boxes = None\n",
    "\n",
    "    image_arr = dataset.images[index]\n",
    "    image = PIL.Image.fromarray(image_arr.astype('uint8'))\n",
    "\n",
    "#     for class_id in detected_roi[:, 4]:\n",
    "#         print(dataset.class_id_to_name[class_id])\n",
    "\n",
    "    display_image_regions(image, detected_roi, gt_boxes,\n",
    "                          class_id_to_name=dataset.class_id_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T11:08:32.330891Z",
     "start_time": "2017-05-17T11:07:21.262882Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n",
      "[Errno 2] No such file or directory: './data/VOC2012/ImageSets/Main/test.txt'\n"
     ]
    }
   ],
   "source": [
    "image_size = (500, 500)\n",
    "all_data = RCNN_All_Data(image_size)\n",
    "# dataset.unload_set('valid')\n",
    "train = RCNN_Set(all_data, 'train')\n",
    "valid = RCNN_Set(all_data, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T11:08:32.341177Z",
     "start_time": "2017-05-17T11:08:32.339397Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T11:09:28.653709Z",
     "start_time": "2017-05-17T11:09:25.636795Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Init the model\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "model = Fast_RCNN_model(dropout_p=0.1).cuda()\n",
    "fast_rcnn_weights_init(model)\n",
    "load_weights(model, 'intermediate/voc/weights-regression-300.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a single image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-17T11:29:00.247Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# images, rois, targets = dataset.next_batch(\n",
    "#     images_per_batch=1,\n",
    "#     roi_batch_size=64,\n",
    "#     use_features=True,\n",
    "#     loop_over=False)\n",
    "\n",
    "all_boxes = test_image(images, rois, dataset, top_class_only=False,\n",
    "                       class_detection_thresh=0.3, nms_thresh=0.3)\n",
    "display_boxes, display_classes = get_display_boxes(all_boxes)\n",
    "if len(display_boxes) == 0:\n",
    "    print('Nothing detected for this image.')\n",
    "else:\n",
    "    display_detections(\n",
    "        RCNN_Set.transform_regions_width_height(display_boxes),\n",
    "        display_classes,\n",
    "        dataset, show_gt_boxes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-17T11:22:48.967213Z",
     "start_time": "2017-05-17T11:22:48.961144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " array([[  94.2329,  264.3162,  142.497 ,  380.0968,    1.    ]], dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([[ 108.1281,  326.2602,  270.4729,  440.2872,    0.7194]], dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([[ 259.9928,  246.2773,  445.7939,  412.4356,    0.9205]], dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32),\n",
       " array([], shape=(0, 5), dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-16T19:44:07.075886Z",
     "start_time": "2017-05-16T19:44:07.072345Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO check how we perform with and without regression targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
